"""A tool for compiling python requirements in for and within Bazel."""

import argparse
import json
import logging
import os
import platform
import shutil
import subprocess
import sys
import tempfile
from io import StringIO
from pathlib import Path
from typing import (
    Any,
    Dict,
    List,
    Mapping,
    NamedTuple,
    Optional,
    Sequence,
    Set,
    Tuple,
    Union,
    cast,
)

# pylint: disable-next=import-error
from python.runfiles import Runfiles

from req_compile.cmdline import (
    IndentFilter,
    _generate_no_candidate_display,
    build_repo,
    write_requirements_file,
)
from req_compile.compile import AllOnlyBinarySet, perform_compile
from req_compile.containers import RequirementsFile
from req_compile.dists import DependencyNode, DistributionCollection
from req_compile.errors import NoCandidateException

_HEADER = """\
################################################################################
## AUTOGENERATED: This file is autogenerated by req-compile.
##
## Python: {python}
## Platform: {platform}
##
## To regenerate this file, use the following command:
##
##    {custom_compile_command}
##
################################################################################

"""


def _deserialize_custom_compile_command(value: str) -> str:
    return json.loads(value)


def parse_args(args: Optional[Sequence[str]]) -> argparse.Namespace:
    """Parse command line arguments"""
    parser = argparse.ArgumentParser()

    parser.add_argument(
        "--requirements_file",
        dest="requirements_files",
        action="append",
        default=[],
        type=str,
        help="Files describing python requirement. (e.g. `requirements.in`).",
    )
    parser.add_argument(
        "--solution",
        type=str,
        help="The solution file which has all compiled outputs of `requirements_files`.",
    )
    parser.add_argument(
        "--output",
        type=Path,
        help="The output path where the new solution should be written.",
    )
    parser.add_argument(
        "--custom_compile_command",
        type=_deserialize_custom_compile_command,
        required=True,
        help="A terminal command which represents how the output solution can be reproduced.",
    )
    parser.add_argument(
        "--upgrade",
        action="store_true",
        help="If set, any existing solution will be ignored during compilation.",
    )
    parser.add_argument(
        "--allow_sdists",
        action="store_true",
        help="If set, the compiled solution will be allowed to include source distributions (sdists) for packages.",
    )
    parser.add_argument(
        "--no_index",
        action="store_true",
        help=(
            "If set, all indexes will be ignored. This will require "
            "the solution file to already satisfy all requirements."
        ),
    )
    parser.add_argument(
        "--wheel-dir",
        "--wheel_dir",
        dest="wheel_dir",
        type=Path,
        help="When set, failed compilations will write wheels for sdist requirements found to this locaiton.",
    )
    parser.add_argument(
        "--verbose",
        action="store_true",
        help="Enable verbose logging.",
    )

    return parser.parse_args(args)


def parse_index_urls(content: str) -> Tuple[Set[str], Set[str], Set[str]]:
    """Parse the index urls from the loaded contents of a requirements file.

    Args:
        content: The loaded contents of a requirements file.

    Returns:
        The index-urls, extra-index-urls, and find-links sets found.
    """
    index_urls: Set[str] = set()
    extra_index_urls: Set[str] = set()
    find_links: Set[str] = set()

    def sanitize(text: str) -> str:
        text, _, _ = text.partition("#")
        return text.strip("= \n\"'")

    for line in content.splitlines():
        if line.startswith(("--extra-index-url", "--extra_index_url")):
            extra_index_urls.add(sanitize(line[len("--extra-index-url") :]))
        if line.startswith(("--index-url", "--index_url")):
            index_urls.add(sanitize(line[len("--index-url") :]))
        if line.startswith(("--find-links", "--find_links")):
            find_links.add(sanitize(line[len("--find-links") :]))

    return index_urls, extra_index_urls, find_links


class CompilationError(Exception):
    """The error type for requirements compilation errors."""

    def __init__(
        self, repo: Any, parent: NoCandidateException
    ) -> None:
        self.repo = repo
        self.parent = parent


class CompilationResult(NamedTuple):
    """A container for compilation results."""

    solution: DistributionCollection
    dep_nodes: Set[DependencyNode]
    repo: Any


def compile_requirements(
    requirements_ins: Mapping[str, Path],
    solution: Path,
    upgrade: bool = False,
    constraints: Optional[Mapping[str, Path]] = None,
    no_index: bool = False,
    only_binary: bool = False,
    promote_extra_index_urls: bool = False,
    wheeldir: Optional[Union[str, Path]] = None,
) -> CompilationResult:
    """Compile a solution for a set of requirements.

    Args:
        requirements_ins: Map of pretty names to input files containing the requirements.
        solution: Input solution file.
        upgrade: Whether or not to ignore the solution when compiling.
        constraints: Constraints to use when compiling a solution.
        no_index: If True, requirements will be compiled with no index and only rely on
            existing constraints in the solutions file.
        only_binary: Ensure the solution is composed exclusively of wheels.
        promote_extra_index_urls: Promote extra index urls to index urls.
        wheeldir: An optional wheeldir to use during compilation.

    Returns:
        The results of the compilation if successful.
    """
    input_reqs: List[RequirementsFile] = []
    index_urls: Set[str] = set()
    extra_index_urls: Set[str] = set()
    find_links: Dict[str, Path] = {}

    # Collect requirement containers
    for name, input_file in requirements_ins.items():
        container = RequirementsFile.from_file(input_file)
        container.name = name
        input_reqs.append(container)

        new_urls, new_extras, new_links = parse_index_urls(
            input_file.read_text(encoding="utf-8")
        )
        index_urls = index_urls.union(new_urls)
        extra_index_urls = extra_index_urls.union(new_extras)
        find_links.update(
            {
                os.path.normpath(input_file.parent / link): solution.parent
                for link in new_links
            }
        )

    # Collect constraint containers
    constraint_reqs = []
    if constraints:
        for name, input_file in constraints.items():
            container = RequirementsFile.from_file(input_file)
            container.name = name
            constraint_reqs.append(container)

    # Identify the wheeldir to use
    external_wheeldir = True
    if not wheeldir:
        wheeldir = Path(tempfile.mkdtemp())
        external_wheeldir = False

    # Generate the solution repository
    repo = build_repo(
        solutions=[] if upgrade else [str(solution)],
        upgrade_packages=[],
        sources=[],
        excluded_sources=[],
        find_links=dict(sorted(find_links.items())),
        index_urls=sorted(
            index_urls | (extra_index_urls if promote_extra_index_urls else set())
        ),
        no_index=no_index,
        wheeldir=wheeldir,
        extra_index_urls=[] if promote_extra_index_urls else sorted(extra_index_urls),
    )

    # Compile the solution
    try:
        compiled_solution, dep_nodes = perform_compile(
            input_reqs=input_reqs,
            repo=repo,
            constraint_reqs=constraint_reqs,
            only_binary=AllOnlyBinarySet() if only_binary else set(),
        )
    except NoCandidateException as exc:
        raise CompilationError(repo=repo, parent=exc) from exc
    finally:
        if external_wheeldir:
            shutil.rmtree(wheeldir)

    return CompilationResult(
        solution=compiled_solution,
        dep_nodes=dep_nodes,
        repo=repo,
    )


def rlocation(runfiles: Runfiles, rlocationpath: str) -> Path:
    """Look up a runfile and ensure the file exists

    Args:
        runfiles: The runfiles object
        rlocationpath: The runfile key

    Returns:
        The requested runifle.
    """
    runfile = runfiles.Rlocation(rlocationpath)
    if not runfile:
        raise FileNotFoundError(f"Failed to find runfile: {rlocationpath}")
    path = Path(runfile)
    if not path.exists():
        raise FileNotFoundError(f"Runfile does not exist: ({rlocationpath}) {path}")
    return path


def _is_wheel(node: DependencyNode) -> Optional[bool]:
    """Determine if a node is a wheel.

    If there isn't sufficient information to determine this, None is returned.
    """
    if not node.metadata:
        return None

    if not node.metadata.candidate:
        return None

    if node.metadata.candidate.type is None:
        return None

    candidate_type = node.metadata.candidate.type
    if candidate_type is None:
        return None
    return getattr(candidate_type, "name", "") == "WHEEL"


def init_logging(verbose: bool) -> None:
    """Initialize logging"""
    logger = logging.getLogger("req_compile")

    if verbose:
        logging.basicConfig(level=logging.DEBUG)
        logger.setLevel(logging.DEBUG)
    else:
        logging.basicConfig(level=logging.INFO)
        logger.setLevel(logging.WARNING)

    logger.getChild("compile").addFilter(IndentFilter())


def wheelmaker_main(args: argparse.Namespace, runfiles: Runfiles) -> None:
    """The entrypoint for building wheels for sdist requirements."""

    if not args.wheel_dir:
        raise ValueError("--wheel-dir is expected to be found in `args`")

    wheel_dir = args.wheel_dir

    requirements_files: Dict[str, Path] = {}
    for requirement_file in args.requirements_files:
        requirements_files[requirement_file] = rlocation(runfiles, requirement_file)
    solution = rlocation(runfiles, args.solution)

    result = compile_requirements(
        requirements_ins=requirements_files,
        solution=solution,
        upgrade=args.upgrade,
        only_binary=False,
        no_index=args.no_index,
    )

    sdists = sorted(req for req in result.solution if _is_wheel(req) is False)

    if not sdists:
        logging.info("No sdist packages found!")
        return

    logging.info("Found sdist packages: %s", sdists)

    logging.info("Building wheels into %s", wheel_dir)

    targets = []
    for req in sdists:
        assert (
            req.metadata
        ), "Requirements will have metadata if they've been identified as sdist."
        if req.metadata.version:
            targets.append(f"{req.key}=={req.metadata.version}")
        else:
            targets.append(req.key)

    # Spawn python with a clean environment
    env = dict(os.environ)
    if "PYTHONPATH" in env:
        del env["PYTHONPATH"]

    proc_result = subprocess.run(
        [
            sys.executable,
            "-m",
            "pip",
            "wheel",
            "--isolated",
            "--no-cache-dir",
            "--no-deps",
            "--disable-pip-version-check",
            "--wheel-dir",
            str(wheel_dir),
        ]
        + sorted(targets),
        check=False,
        env=env,
        stderr=None if args.verbose else subprocess.STDOUT,
        stdout=None if args.verbose else subprocess.PIPE,
    )

    if proc_result.returncode:
        print(proc_result.stdout.decode("utf-8"), file=sys.stderr)
        sys.exit(proc_result.returncode)


def compile_main(args: argparse.Namespace, runfiles: Runfiles) -> None:
    """The entrypoint for performing compilation."""

    requirements_files: Dict[str, Path] = {}
    for requirement_file in args.requirements_files:
        requirements_files[requirement_file] = rlocation(runfiles, requirement_file)
    solution = rlocation(runfiles, args.solution)

    # Compile all requirements
    try:
        result = compile_requirements(
            requirements_ins=requirements_files,
            solution=solution,
            upgrade=args.upgrade,
            only_binary=False if args.allow_sdists else True,
            no_index=args.no_index,
        )
    except CompilationError as exc:
        _generate_no_candidate_display(
            exc.parent.req,
            exc.repo,
            cast(DistributionCollection, exc.parent.results),
            exc.parent,
        )

        if args.wheel_dir:
            logging.info("Attempting to build wheels for sdist dependencies.")
            wheelmaker_main(args, runfiles)
        sys.exit(1)

    # Write out the requirements file if a location was provided.
    if args.output:
        buffer = StringIO()
        buffer.write(
            _HEADER.format(
                custom_compile_command=args.custom_compile_command,
                python=platform.python_version(),
                platform=platform.system(),
            )
        )
        write_requirements_file(
            results=result.solution,
            roots=result.dep_nodes,
            repo=result.repo,
            urls=True,
            hashes=True,
            multiline=True,
            write_to=buffer,
        )

        if str(args.output).startswith(".."):
            print(
                "WARNING: Outputs cannot be outside the current workspace.",
                file=sys.stderr,
            )
            print(
                f"WARNING: Output {args.output} will not be written but instead printed.",
                file=sys.stderr,
            )
            print(buffer.getvalue)
        else:
            workspace_dir = Path(os.environ["BUILD_WORKSPACE_DIRECTORY"])
            output = workspace_dir / args.output
            output.write_text(
                buffer.getvalue(),
                encoding="utf-8",
            )
            if args.verbose:
                print(output.read_text(encoding="utf-8"))
            print(f"Successfully compiled {output}")


def main() -> None:
    """The main entrypoint."""

    runfiles = Runfiles.Create()
    if not runfiles:
        raise EnvironmentError("Failed to locate runfiles.")

    argv = None
    if "PY_REQ_COMPILER_ARGS_FILE" in os.environ:
        args_file = rlocation(runfiles, os.environ["PY_REQ_COMPILER_ARGS_FILE"])
        argv = args_file.read_text(encoding="utf-8").splitlines() + sys.argv[1:]

    args = parse_args(argv)

    init_logging(args.verbose)

    compile_main(args, runfiles)


if __name__ == "__main__":
    main()
