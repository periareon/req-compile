"""A tool for compiling python requirements in for and within Bazel."""

import argparse
import json
import logging
import os
import platform
import shutil
import sys
import tempfile
from io import StringIO
from pathlib import Path
from typing import (
    Dict,
    List,
    Mapping,
    NamedTuple,
    Optional,
    Sequence,
    Set,
    Tuple,
    Union,
    cast,
)

from rules_python.python.runfiles import Runfiles  # pylint: disable=import-error

from req_compile.cmdline import (
    IndentFilter,
    _generate_no_candidate_display,
    build_repo,
    write_requirements_file,
)
from req_compile.compile import AllOnlyBinarySet, perform_compile
from req_compile.containers import RequirementsFile
from req_compile.dists import DependencyNode, DistributionCollection
from req_compile.errors import NoCandidateException
from req_compile.repos import Repository

_HEADER = """\
################################################################################
## AUTOGENERATED: This file is autogenerated by req-compile.
##
## Python: {python}
## Platform: {platform}
##
## To regenerate this file, use the following command:
##
##    {custom_compile_command}
##
################################################################################

"""


def _deserialize_custom_compile_command(value: str) -> str:
    return json.loads(value)


def parse_args(args: Optional[Sequence[str]]) -> argparse.Namespace:
    """Parse command line arguments"""
    parser = argparse.ArgumentParser()

    parser.add_argument(
        "--requirements_file",
        dest="requirements_files",
        action="append",
        default=[],
        type=str,
        help="Files describing python requirement. (e.g. `requirements.in`).",
    )
    parser.add_argument(
        "--solution",
        type=str,
        help="The solution file which has all compiled outputs of `requirements_files`.",
    )
    parser.add_argument(
        "--output",
        type=Path,
        help="The output path where the new solution should be written.",
    )
    parser.add_argument(
        "--custom_compile_command",
        type=_deserialize_custom_compile_command,
        required=True,
        help="A terminal command which represents how the output solution can be reproduced.",
    )
    parser.add_argument(
        "--upgrade",
        action="store_true",
        help="If set, any existing solution will be ignored during compilation.",
    )
    parser.add_argument(
        "--allow_sdists",
        action="store_true",
        help="If set, the compiled solution will be allowed to include source distributions (sdists) for packages.",
    )
    parser.add_argument(
        "--no_index",
        action="store_true",
        help=(
            "If set, all indexes will be ignored. This will require "
            "the solution file to already satisfy all requirements."
        ),
    )
    parser.add_argument(
        "--verbose",
        action="store_true",
        help="Enable verbose logging.",
    )

    return parser.parse_args(args)


def parse_index_urls(content: str) -> Tuple[Set[str], Set[str], Set[str]]:
    """Parse the index urls from the loaded contents of a requirements file.

    Args:
        content: The loaded contents of a requirements file.

    Returns:
        The index-urls, extra-index-urls, and find-links sets found.
    """
    index_urls: Set[str] = set()
    extra_index_urls: Set[str] = set()
    find_links: Set[str] = set()

    def sanitize(text: str) -> str:
        text, _, _ = text.partition("#")
        return text.strip("= \n\"'")

    for line in content.splitlines():
        if line.startswith(("--extra-index-url", "--extra_index_url")):
            extra_index_urls.add(sanitize(line[len("--extra-index-url") :]))
        if line.startswith(("--index-url", "--index_url")):
            index_urls.add(sanitize(line[len("--index-url") :]))
        if line.startswith(("--find-links", "--find_links")):
            find_links.add(sanitize(line[len("--find-links") :]))

    return index_urls, extra_index_urls, find_links


class CompilationError(Exception):
    """The error type for requirements compilation errors."""

    def __init__(self, repo: Repository, parent: NoCandidateException) -> None:
        self.repo = repo
        self.parent = parent


class CompilationResult(NamedTuple):
    """A container for compilation results."""

    solution: DistributionCollection
    dep_nodes: Set[DependencyNode]
    repo: Repository


def compile_requirements(
    requirements_ins: Mapping[str, Path],
    solution: Path,
    upgrade: bool = False,
    constraints: Optional[Mapping[str, Path]] = None,
    no_index: bool = False,
    only_binary: bool = False,
    promote_extra_index_urls: bool = False,
    wheeldir: Optional[Union[str, Path]] = None,
) -> CompilationResult:
    """_summary_

    Args:
        requirements_ins (Mapping[str, Path]): _description_
        solution (Optional[Path], optional): _description_. Defaults to None.
        constraints (Optional[Mapping[str, Path]], optional): _description_. Defaults to None.
        no_index (bool, optional): _description_. Defaults to False.
        only_binary (bool, optional): _description_. Defaults to False.
        promote_extra_index_urls (bool, optional): _description_. Defaults to False.
        wheeldir (Optional[Union[str, Path]], optional): _description_. Defaults to None.

    Returns:
        _type_: _description_
    """
    input_reqs: List[RequirementsFile] = []
    index_urls: Set[str] = set()
    extra_index_urls: Set[str] = set()
    find_links: Dict[str, Path] = {}

    # Collect requirement containers
    for name, input_file in requirements_ins.items():
        container = RequirementsFile.from_file(input_file)
        container.name = name
        input_reqs.append(container)

        new_urls, new_extras, new_links = parse_index_urls(
            input_file.read_text(encoding="utf-8")
        )
        index_urls = index_urls.union(new_urls)
        extra_index_urls = extra_index_urls.union(new_extras)
        find_links.update(
            {
                os.path.normpath(input_file.parent / link): solution.parent
                for link in new_links
            }
        )

    # Collect constraint containers
    constraint_reqs = []
    if constraints:
        for name, input_file in constraints.items():
            container = RequirementsFile.from_file(input_file)
            container.name = name
            constraint_reqs.append(container)

    # Identify the wheeldir to use
    external_wheeldir = True
    if not wheeldir:
        wheeldir = Path(tempfile.mkdtemp())
        external_wheeldir = False

    # Generate the solution repository
    repo = build_repo(
        solutions=[] if upgrade else [str(solution)],
        upgrade_packages=[],
        sources=[],
        excluded_sources=[],
        find_links=dict(sorted(find_links.items())),
        index_urls=sorted(
            index_urls | (extra_index_urls if promote_extra_index_urls else set())
        ),
        no_index=no_index,
        wheeldir=wheeldir,
        extra_index_urls=[] if promote_extra_index_urls else sorted(extra_index_urls),
    )

    # Compile the solution
    try:
        compiled_solution, dep_nodes = perform_compile(
            input_reqs=input_reqs,
            repo=repo,
            constraint_reqs=constraint_reqs,
            only_binary=AllOnlyBinarySet() if only_binary else set(),
        )
    except NoCandidateException as exc:
        raise CompilationError(repo=repo, parent=exc) from exc
    finally:
        if external_wheeldir:
            shutil.rmtree(wheeldir)

    return CompilationResult(
        solution=compiled_solution,
        dep_nodes=dep_nodes,
        repo=repo,
    )


def rlocation(runfiles: Runfiles, rlocationpath: str) -> Path:
    """Look up a runfile and ensure the file exists

    Args:
        runfiles: The runfiles object
        rlocationpath: The runfile key

    Returns:
        The requested runifle.
    """
    runfile = runfiles.Rlocation(rlocationpath)
    if not runfile:
        raise FileNotFoundError(f"Failed to find runfile: {rlocationpath}")
    path = Path(runfile)
    if not path.exists():
        raise FileNotFoundError(f"Runfile does not exist: ({rlocationpath}) {path}")
    return path


def main() -> None:
    """The main entrypoint."""

    runfiles = Runfiles.Create()
    if not runfiles:
        raise EnvironmentError("Failed to locate runfiles.")

    argv = None
    if "PY_REQ_COMPILER_ARGS_FILE" in os.environ:
        args_file = rlocation(runfiles, os.environ["PY_REQ_COMPILER_ARGS_FILE"])
        argv = args_file.read_text(encoding="utf-8").splitlines() + sys.argv[1:]

    args = parse_args(argv)

    compile_main(args, runfiles)


def compile_main(args: argparse.Namespace, runfiles: Runfiles) -> None:
    """The entrypoint for performing compilation"""
    if args.verbose:
        logger = logging.getLogger("req_compile")

        logging.basicConfig(level=logging.DEBUG, stream=sys.stderr)
        logger.setLevel(logging.DEBUG)

        logger.getChild("compile").addFilter(IndentFilter())

    requirements_files: Dict[str, Path] = {}
    for requirement_file in args.requirements_files:
        requirements_files[requirement_file] = rlocation(runfiles, requirement_file)
    solution = rlocation(runfiles, args.solution)

    # Compile all requirements
    try:
        result = compile_requirements(
            requirements_ins=requirements_files,
            solution=solution,
            upgrade=args.upgrade,
            only_binary=False if args.allow_sdists else True,
            no_index=args.no_index,
        )
    except CompilationError as exc:
        _generate_no_candidate_display(
            exc.parent.req,
            exc.repo,
            cast(DistributionCollection, exc.parent.results),
            exc.parent,
        )
        sys.exit(1)

    # Write out the requirements file if a location was provided.
    if args.output:
        buffer = StringIO()
        buffer.write(
            _HEADER.format(
                custom_compile_command=args.custom_compile_command,
                python=platform.python_version(),
                platform=platform.system(),
            )
        )
        write_requirements_file(
            results=result.solution,
            roots=result.dep_nodes,
            repo=result.repo,
            urls=True,
            hashes=True,
            multiline=True,
            write_to=buffer,
        )

        if str(args.output).startswith(".."):
            print(
                "WARNING: Outputs cannot be outside the current workspace.",
                file=sys.stderr,
            )
            print(
                f"WARNING: Output {args.output} will not be written but instead printed.",
                file=sys.stderr,
            )
            print(buffer.getvalue)
        else:
            workspace_dir = Path(os.environ["BUILD_WORKSPACE_DIRECTORY"])
            output = workspace_dir / args.output
            output.write_text(
                buffer.getvalue(),
                encoding="utf-8",
            )
            if args.verbose:
                print(output.read_text(encoding="utf-8"))
            print(f"Successfully compiled {output}")


if __name__ == "__main__":
    main()
